{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n",
      "c:\\python27\\lib\\site-packages\\keras\\backend\\cntk_backend.py:18: UserWarning: CNTK backend warning: GPU is not detected. CNTK's CPU version is not fully optimized,please run with GPU to get better performance.\n",
      "  'CNTK backend warning: GPU is not detected. '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from keras.models import model_from_json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forecast_lstm(model, batch_size, X):\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    return yhat[0,0]\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "\n",
    "def invert_scale(scaler, X, value):\n",
    "    new_row = [x for x in X] + [value]\n",
    "    array = np.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]\n",
    "\n",
    "def scale(test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    #scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    #train = train.reshape(train.shape[0], train.shape[1])\n",
    "    #train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.fit_transform(test)\n",
    "    return scaler, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_b = pd.read_csv('data/weather_UTC_2012-2016_Berlin.csv', sep=';', decimal=',')\n",
    "weather_b.VALUE_TIME = pd.to_datetime(weather_b.VALUE_TIME)\n",
    "weather_b.set_index('VALUE_TIME', inplace=True)\n",
    "\n",
    "weather_m = pd.read_csv('data/weather_UTC_2012-2016_Munich.csv', sep=';', decimal=',')\n",
    "weather_m.VALUE_TIME = pd.to_datetime(weather_m.VALUE_TIME)\n",
    "weather_m.set_index('VALUE_TIME', inplace=True)\n",
    "\n",
    "weather_d = pd.read_csv('data/weather_UTC_2012-2016_Dusseldorf.csv', sep=';', decimal=',')\n",
    "weather_d.VALUE_TIME = pd.to_datetime(weather_d.VALUE_TIME)\n",
    "weather_d.set_index('VALUE_TIME', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "energy = pd.read_csv('data/production_consumption_2012_2016_scaled.csv', sep=';', decimal=',')\n",
    "energy['timestamp'] = pd.to_datetime(energy['cet_cest_timestamp'])\n",
    "energy.drop(['utc_timestamp', 'cet_cest_timestamp'], axis=1, inplace=True)\n",
    "energy.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\keras\\backend\\cntk_backend.py:2337: UserWarning: CNTK backend warning: CNTK version not detected. Will using CNTK 2.0 GA as default.\n",
      "  'CNTK backend warning: CNTK version not detected. '\n",
      "c:\\python27\\lib\\site-packages\\keras\\backend\\cntk_backend.py:2337: UserWarning: CNTK backend warning: CNTK version not detected. Will using CNTK 2.0 GA as default.\n",
      "  'CNTK backend warning: CNTK version not detected. '\n",
      "c:\\python27\\lib\\site-packages\\keras\\backend\\cntk_backend.py:2337: UserWarning: CNTK backend warning: CNTK version not detected. Will using CNTK 2.0 GA as default.\n",
      "  'CNTK backend warning: CNTK version not detected. '\n"
     ]
    }
   ],
   "source": [
    "pred_wind = joblib.load('models/wind_prediction_model.sav')\n",
    "pred_sun = joblib.load('models/solar_prediction_model.sav')\n",
    "\n",
    "# load RNN model\n",
    "json_file = open('models/consumption_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "pred_consumption = model_from_json(loaded_model_json)\n",
    "pred_consumption.load_weights(\"models/consumption_model_weights.h5\")\n",
    "pred_consumption.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_2m</th>\n",
       "      <th>precip_1h</th>\n",
       "      <th>global_rad</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VALUE_TIME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-12-31 00:00:00</th>\n",
       "      <td>-1.6</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31 01:00:00</th>\n",
       "      <td>-1.9</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31 02:00:00</th>\n",
       "      <td>-2.1</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31 03:00:00</th>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31 04:00:00</th>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     t_2m  precip_1h  global_rad  wind_speed_10m\n",
       "VALUE_TIME                                                      \n",
       "2011-12-31 00:00:00  -1.6       0.16         0.0            17.1\n",
       "2011-12-31 01:00:00  -1.9       0.08         0.0            14.7\n",
       "2011-12-31 02:00:00  -2.1       0.08         0.0            12.3\n",
       "2011-12-31 03:00:00  -2.4       0.08         0.0            10.0\n",
       "2011-12-31 04:00:00  -2.4       0.03         0.0             9.7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost_function(params):\n",
    "    p_hat = params[0]\n",
    "    c_hat = params[1]\n",
    "    b_hat = params[2]\n",
    "    \n",
    "    b = []\n",
    "    for i in range(24):\n",
    "        b[i] = c_hat[i] - p_hat[i] - b_hat[i]\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 25 into shape (1,1,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-66d96e6c6ecf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# make one-step forecast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mX_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforecast_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_consumption\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;31m# invert scaling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minvert_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-263f770bbcee>\u001b[0m in \u001b[0;36mforecast_lstm\u001b[1;34m(model, batch_size, X)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforecast_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0myhat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 25 into shape (1,1,1)"
     ]
    }
   ],
   "source": [
    "base = datetime.datetime(2016, 1, 1)\n",
    "battery_pred = np.zeros(24)\n",
    "lag = 24\n",
    "y0 = 0\n",
    "for day in [base + datetime.timedelta(days=x) for x in range(0, 10)]:\n",
    "    next_day =  day+datetime.timedelta(days=1)\n",
    "    \n",
    "    X_solar = np.array(pd.concat([weather_m[(weather_m.index >= day) & (weather_m.index < next_day)][['global_rad']],\n",
    "                            weather_b[(weather_b.index >= day) & (weather_b.index < next_day)][['global_rad']],\n",
    "                            weather_d[(weather_d.index >= day) & (weather_d.index < next_day)][['global_rad']]\n",
    "                           ], axis=1)\n",
    "                )\n",
    "    \n",
    "    X_wind = np.array(pd.concat([weather_m[(weather_m.index >= day) & (weather_m.index < next_day)][['wind_speed_10m']],\n",
    "                            weather_b[(weather_b.index >= day) & (weather_b.index < next_day)][['wind_speed_10m']],\n",
    "                            weather_d[(weather_d.index >= day) & (weather_d.index < next_day)][['wind_speed_10m']]\n",
    "                           ], axis=1)\n",
    "                )\n",
    "    \n",
    "    X = weather_b[(weather_b.index >= day) & (weather_b.index < next_day)].merge(\n",
    "        weather_d[(weather_d.index >= day) & (weather_d.index < next_day)], left_index=True, right_index=True).merge(\n",
    "        weather_m[(weather_m.index >= day) & (weather_m.index < next_day)], left_index=True, right_index=True)\n",
    "    X_cons = series_to_supervised(X.values, 1, 1, True)\n",
    "    \n",
    "    scaler, X_scaled = scale(np.array(X_cons))\n",
    "    consumption_pred = []\n",
    "    for i in range(len(X_scaled)):\n",
    "        # make one-step forecast\n",
    "        X_i = np.append(X_scaled[i], y0).reshape(1,1,25)\n",
    "        yhat = forecast_lstm(pred_consumption, 1, X_i)\n",
    "        # invert scaling\n",
    "        yhat = invert_scale(scaler, X_i, yhat)\n",
    "        # store forecast\n",
    "        consumption_pred.append(yhat)\n",
    "        \n",
    "    consumption =  np.array(energy[(energy.index >= day) & (energy.index < next_day)]['consumption'])\n",
    "    '''\n",
    "    solar = np.array(energy[(energy.index >= day) & (energy.index < next_day)]['solarprod'])\n",
    "    wind =  np.array(energy[(energy.index >= day) & (energy.index < next_day)]['windprod'])\n",
    "    production = solar + wind\n",
    "    \n",
    "    model = ARIMA(consumption, order=(2, 0, 1))\n",
    "    ARIMA_fitted = model.fit(disp=-1)\n",
    "    start_idx = consumption.shape[0]\n",
    "    end_idx = start_idx + lag - 1\n",
    "    \n",
    "    wind_pred = pred_wind.predict(X_wind)\n",
    "    solar_pred = pred_sun.predict(X_solar)\n",
    "    production_pred = solar_pred + wind_pred\n",
    "    consumption_pred = ARIMA_fitted.predict(start=start_idx, end=end_idx).reshape(-1, 1)\n",
    "    \n",
    "    #battery = minimize(cost_function, [production_pred, consumption_pred, battery_pred], method='nelder-mead')\n",
    "    battery = production_pred - consumption_pred - battery_pred\n",
    "    battery_pred = battery\n",
    "    '''\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(16,10))\n",
    "    plt.plot(consumption_pred, linestyle='--' ,label='pred_consumption')\n",
    "    plt.plot(consumption, color='red')\n",
    "#plt.plot(consumption_pred, color='red', label='pred_consumption')\n",
    "#plt.plot(battery_pred, color='blue', label='battery', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1L, 1L, 25L)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(X_scaled[i], y0).reshape(1,1,25).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24L,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        , -1.        ,  0.51428571, -0.87096774,\n",
       "        -1.        , -1.        ,  0.31288344,  0.66666667, -1.        ,\n",
       "        -1.        , -0.51785714,  1.        , -1.        , -1.        ,\n",
       "         0.        , -1.        , -1.        , -1.        ,  0.16167665,\n",
       "         0.71428571, -1.        , -1.        , -0.75206612,  0.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(X_scaled[i], y0).reshape(1,1,25)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
